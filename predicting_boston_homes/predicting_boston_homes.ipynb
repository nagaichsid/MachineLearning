{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Home Value and Nox in Boston Homes\n",
    "CS 6140 Midterm\n",
    "Author: Sid Nagaich\n",
    "\n",
    "Problem 3: Using the Boston data set, build a linear regressor that predicts NOX and another one that predicts median home value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data\n",
    "Here we simply import some libraries, suppress warnings, and view the provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     ptratio       b  lstat  medv  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# read data\n",
    "data = pd.read_csv(\"BostonHousing.csv\")\n",
    "\n",
    "# show data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Data\n",
    "Here we will create two data sets to use for our two models. One to predict median home value and one to predict NOX. We drop the corresponding columns in each dataset so that our model does not train on the data which it is trying to predict. Since this is a smaller data set, we reserve 20% of it for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set for predicting medv\n",
    "medv_data = data.copy().drop(columns='medv')\n",
    "\n",
    "# data set for predicting NOX\n",
    "nox_data = data.copy().drop(columns='nox')\n",
    "\n",
    "# medv is what we want to predict in one model\n",
    "medv_y = data.loc[:,'medv']\n",
    "\n",
    "# grab column headers for predicting medv\n",
    "medv_predictors = [p for p in medv_data.columns]\n",
    "\n",
    "# x is data with which we will predict y\n",
    "medv_x = data.loc[:, medv_predictors]\n",
    "\n",
    "# grab column headers for predicting nox\n",
    "nox_predictors = [p for p in nox_data.columns]\n",
    "\n",
    "# nox is what we want to predict in other model\n",
    "nox_y = data.loc[:,'nox']\n",
    "\n",
    "# x is data with which we will predict y\n",
    "nox_x = data.loc[:, nox_predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# shuffle medv data before splitting 75/25\n",
    "medv_train_x, medv_test_x, medv_train_y, medv_test_y = train_test_split(medv_x, medv_y, test_size=0.25, random_state=13)\n",
    "\n",
    "# shuffle and split nox data\n",
    "nox_train_x, nox_test_x, nox_train_y, nox_test_y = train_test_split(nox_x, nox_y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Gradient Boosted Trees\n",
    "We use gradient boosted trees as a regressor to predict median home value and Nox. Hyperparameters have been tuned.\n",
    "We normalzie our data as Gradient Boosting is susceptible to overfitting -- see discussion at end of notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model predicts Median Home Value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Med Value: 12.0 | Predicted Med Value: 14.473995517789293\n",
      "Actual Med Value: 15.2 | Predicted Med Value: 15.490871528891724\n",
      "Actual Med Value: 21.0 | Predicted Med Value: 20.278436040939003\n",
      "Actual Med Value: 24.0 | Predicted Med Value: 27.998183576064935\n",
      "Actual Med Value: 19.4 | Predicted Med Value: 20.158831577276732\n",
      "Actual Med Value: 22.2 | Predicted Med Value: 22.58281887408838\n",
      "Actual Med Value: 23.3 | Predicted Med Value: 22.978760152883776\n",
      "Actual Med Value: 15.6 | Predicted Med Value: 15.703294825333597\n",
      "Actual Med Value: 20.8 | Predicted Med Value: 20.368323535984253\n",
      "Actual Med Value: 13.8 | Predicted Med Value: 21.578153209603638\n",
      "Actual Med Value: 19.6 | Predicted Med Value: 18.31828689277949\n",
      "\n",
      "model score: 0.8913935471647142\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Gradient Boosted Trees\n",
    "gbt = make_pipeline(StandardScaler(), GradientBoostingRegressor(n_estimators=6500, learning_rate=0.05, max_depth=9, subsample=0.85, \n",
    "                                validation_fraction=0.2, n_iter_no_change=20, max_features='log2',\n",
    "                                random_state=13)).fit(medv_train_x, medv_train_y)\n",
    "\n",
    "gbt.score(medv_test_x, medv_test_y)\n",
    "\n",
    "gbt_predictions = gbt.predict(medv_test_x)\n",
    "\n",
    "# show some predictions\n",
    "i = 0\n",
    "for pre in medv_test_y:\n",
    "    if (i > 10): break\n",
    "    print(\"Actual Med Value: \" + str(pre) + \" | Predicted Med Value: \" + str(gbt_predictions[i]))\n",
    "    i += 1\n",
    "\n",
    "# model score\n",
    "print(\"\\nmodel score: \" + str(gbt.score(medv_test_x, medv_test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second model predict NOX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Nox: 0.51 | Predicted Nox: 0.5152136106645683\n",
      "Actual Nox: 0.447 | Predicted Nox: 0.4530425422254208\n",
      "Actual Nox: 0.609 | Predicted Nox: 0.6146453499443025\n",
      "Actual Nox: 0.413 | Predicted Nox: 0.42647379675314706\n",
      "Actual Nox: 0.713 | Predicted Nox: 0.7082267547123053\n",
      "Actual Nox: 0.437 | Predicted Nox: 0.5016121001357734\n",
      "Actual Nox: 0.544 | Predicted Nox: 0.5379573938611847\n",
      "Actual Nox: 0.624 | Predicted Nox: 0.625316137214737\n",
      "Actual Nox: 0.532 | Predicted Nox: 0.6723139543336586\n",
      "Actual Nox: 0.585 | Predicted Nox: 0.5703054871263784\n",
      "Actual Nox: 0.55 | Predicted Nox: 0.5377643163524639\n",
      "\n",
      "model score: 0.9023741809370741\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosted Trees\n",
    "gbt = make_pipeline(StandardScaler(), GradientBoostingRegressor(n_estimators=5000, learning_rate=0.05, max_depth=9, subsample=0.75, \n",
    "                                validation_fraction=0.1, max_features=4, \n",
    "                                random_state=13)).fit(nox_train_x, nox_train_y)\n",
    "\n",
    "gbt.score(nox_test_x, nox_test_y)\n",
    "\n",
    "gbt_predictions = gbt.predict(nox_test_x)\n",
    "\n",
    "# show some predictions\n",
    "i = 0\n",
    "for pre in nox_test_y:\n",
    "    if (i > 10): break\n",
    "    print(\"Actual Nox: \" + str(pre) + \" | Predicted Nox: \" + str(gbt_predictions[i]))\n",
    "    i += 1\n",
    "\n",
    "# model score\n",
    "print(\"\\nmodel score: \" + str(gbt.score(nox_test_x, nox_test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Stochastic Gradient Descent\n",
    "I wanted to compare the GBT models with an SGD model, as the GBT models are susceptible to overfitting. Despite normalization of the data, I believe the GBT models are overfit and the SGD models may generalize better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Median Home Value with SGD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Med Value: 12.0 | Predicted Med Value: 10.636018151929182\n",
      "Actual Med Value: 15.2 | Predicted Med Value: 19.660237283477716\n",
      "Actual Med Value: 21.0 | Predicted Med Value: 20.95375964748582\n",
      "Actual Med Value: 24.0 | Predicted Med Value: 30.535320073523046\n",
      "Actual Med Value: 19.4 | Predicted Med Value: 23.103766801291172\n",
      "Actual Med Value: 22.2 | Predicted Med Value: 22.376591535957\n",
      "Actual Med Value: 23.3 | Predicted Med Value: 21.87014734673475\n",
      "Actual Med Value: 15.6 | Predicted Med Value: 22.304824629360272\n",
      "Actual Med Value: 20.8 | Predicted Med Value: 19.390727996318866\n",
      "Actual Med Value: 13.8 | Predicted Med Value: -0.3528533659774524\n",
      "Actual Med Value: 19.6 | Predicted Med Value: 19.444555013979297\n",
      "\n",
      "model score: 0.7133038492950874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "reg = make_pipeline(StandardScaler(), SGDRegressor(max_iter=1000, tol=1e-3)).fit(medv_train_x, medv_train_y)\n",
    "\n",
    "reg.score(medv_test_x, medv_test_y)\n",
    "\n",
    "reg_predictions = reg.predict(medv_test_x)\n",
    "\n",
    "# show some predictions\n",
    "i = 0\n",
    "for pre in medv_test_y:\n",
    "    if (i > 10): break\n",
    "    print(\"Actual Med Value: \" + str(pre) + \" | Predicted Med Value: \" + str(reg_predictions[i]))\n",
    "    i += 1\n",
    "\n",
    "# model score\n",
    "print(\"\\nmodel score: \" + str(reg.score(medv_test_x, medv_test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting NOX with SGD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Nox: 0.51 | Predicted Nox: 0.5577290054655057\n",
      "Actual Nox: 0.447 | Predicted Nox: 0.4813754046100445\n",
      "Actual Nox: 0.609 | Predicted Nox: 0.7004422661708929\n",
      "Actual Nox: 0.413 | Predicted Nox: 0.4487596178238911\n",
      "Actual Nox: 0.713 | Predicted Nox: 0.6687792802829436\n",
      "Actual Nox: 0.437 | Predicted Nox: 0.558224458014589\n",
      "Actual Nox: 0.544 | Predicted Nox: 0.5548999635133647\n",
      "Actual Nox: 0.624 | Predicted Nox: 0.6389056812855617\n",
      "Actual Nox: 0.532 | Predicted Nox: 0.6478431411788487\n",
      "Actual Nox: 0.585 | Predicted Nox: 0.57356113769577\n",
      "Actual Nox: 0.55 | Predicted Nox: 0.6387377232981007\n",
      "\n",
      "model score: 0.7473944621687161\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosted Trees\n",
    "reg = make_pipeline(StandardScaler(), SGDRegressor(max_iter=1000, tol=1e-3)).fit(nox_train_x, nox_train_y)\n",
    "\n",
    "reg.score(nox_test_x, nox_test_y)\n",
    "\n",
    "reg_predictions = reg.predict(nox_test_x)\n",
    "\n",
    "# show some predictions\n",
    "i = 0\n",
    "for pre in nox_test_y:\n",
    "    if (i > 10): break\n",
    "    print(\"Actual Nox: \" + str(pre) + \" | Predicted Nox: \" + str(reg_predictions[i]))\n",
    "    i += 1\n",
    "\n",
    "# model score\n",
    "print(\"\\nmodel score: \" + str(reg.score(nox_test_x, nox_test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion:\n",
    "The gradient boosted trees are likely overfitted to the training data. Having more data for validation purposes could potentially solve this. While it *could* be the case that GBTs perform better than SGD here, I believe the SGD models would generalize better in real-world application, despite their lower scores."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2534124e6b5484b07d693069707edd7e20e1e4151164c7fbebaefa7e2b3a2be4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
